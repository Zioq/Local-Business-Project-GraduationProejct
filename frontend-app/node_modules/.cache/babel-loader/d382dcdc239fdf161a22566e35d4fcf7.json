{"ast":null,"code":"import React, { useEffect } from \"react\";\n\nfunction voiceRecognition() {\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const recognition = new SpeechRecognition();\n  recognition.start();\n\n  const voiceCommands = () => {\n    recognition.start = () => {\n      console.log(`Voice is activate`);\n    };\n  }; //Check the voice recognition activate\n\n\n  recognition.onresult = e => {\n    let current = e.resultIndex;\n    var transcript = e.results[current][0].transcript;\n  };\n\n  return console.log(transcript);\n}\n\nexport default voiceRecognition;","map":{"version":3,"sources":["/Users/mac/Desktop/DOUGLAS FALL 2020/CSIS 4495 Applied  Research Project/Full_Stack_Project/frontend-app/src/components/VoiceRecognition.js"],"names":["React","useEffect","voiceRecognition","SpeechRecognition","window","webkitSpeechRecognition","recognition","start","voiceCommands","console","log","onresult","e","current","resultIndex","transcript","results"],"mappings":"AAAA,OAAOA,KAAP,IAAeC,SAAf,QAA+B,OAA/B;;AAEA,SAASC,gBAAT,GAA4B;AACxB,QAAMC,iBAAiB,GAAGC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBAA7D;AACA,QAAMC,WAAW,GAAG,IAAIH,iBAAJ,EAApB;AACAG,EAAAA,WAAW,CAACC,KAAZ;;AAEA,QAAMC,aAAa,GAAG,MAAK;AACvBF,IAAAA,WAAW,CAACC,KAAZ,GAAoB,MAAK;AACrBE,MAAAA,OAAO,CAACC,GAAR,CAAa,mBAAb;AACH,KAFD;AAGH,GAJD,CALwB,CAWxB;;;AACAJ,EAAAA,WAAW,CAACK,QAAZ,GAAwBC,CAAD,IAAM;AACzB,QAAIC,OAAO,GAAGD,CAAC,CAACE,WAAhB;AAEA,QAAIC,UAAU,GAAGH,CAAC,CAACI,OAAF,CAAUH,OAAV,EAAmB,CAAnB,EAAsBE,UAAvC;AACH,GAJD;;AAKA,SAEIN,OAAO,CAACC,GAAR,CAAYK,UAAZ,CAFJ;AAQH;;AAED,eAAeb,gBAAf","sourcesContent":["import React, {useEffect} from \"react\";\n\nfunction voiceRecognition() {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    const recognition = new SpeechRecognition();\n    recognition.start();\n    \n    const voiceCommands = ()=> {\n        recognition.start = () =>{\n            console.log(`Voice is activate`);\n        }\n    };\n    \n    //Check the voice recognition activate\n    recognition.onresult = (e) =>{\n        let current = e.resultIndex;\n        \n        var transcript = e.results[current][0].transcript;\n    }\n    return(\n      \n        console.log(transcript)\n    \n    );\n\n    \n\n}\n\nexport default voiceRecognition;\n"]},"metadata":{},"sourceType":"module"}